# CI Workflow - Lancer les tests et entraÃ®ner le modÃ¨le

name: CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test-data:
    runs-on: ubuntu-latest
    name: Tester la qualitÃ© des donnÃ©es
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Installer Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Installer les dÃ©pendances
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: GÃ©nÃ©rer les donnÃ©es
        run: python data/generate_data.py
      
      - name: Tests de qualitÃ© des donnÃ©es
        run: pytest tests/test_data.py -v

  train-model:
    runs-on: ubuntu-latest
    name: EntraÃ®ner et Ã©valuer le modÃ¨le
    needs: test-data
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Installer Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Installer les dÃ©pendances
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: GÃ©nÃ©rer les donnÃ©es
        run: python data/generate_data.py
      
      - name: EntraÃ®ner le modÃ¨le
        run: python src/train.py
      
      - name: Ã‰valuer le modÃ¨le
        run: python src/evaluate.py
      
      - name: Tests du modÃ¨le
        run: pytest tests/test_model.py -v
      
      - name: Uploader le modÃ¨le
        uses: actions/upload-artifact@v3
        with:
          name: model-artifacts
          path: models/
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CI PIPELINE â€” IntÃ©gration Continue pour le modÃ¨le de Churn ML
#  Fichier : .github/workflows/ci.yml
#
#  Ce pipeline se dÃ©clenche Ã  chaque push et vÃ©rifie :
#  1. La qualitÃ© du code Python
#  2. La validitÃ© des donnÃ©es
#  3. L'entraÃ®nement et les performances du modÃ¨le
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

name: "CI â€” Churn ML Pipeline"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DÃ‰CLENCHEURS
# Quand est-ce que ce workflow se lance automatiquement ?
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
on:
  push:
    branches:
      - main       # Chaque push sur la branche principale
      - develop    # Chaque push sur la branche de dÃ©veloppement
      - "feature/*"  # Chaque push sur une branche feature/...
  pull_request:
    branches:
      - main       # Chaque Pull Request vers main

# Optionnel : lancer le pipeline manuellement depuis GitHub
  workflow_dispatch:

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VARIABLES D'ENVIRONNEMENT GLOBALES
# Disponibles dans tous les jobs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
env:
  PYTHON_VERSION: "3.10"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# JOBS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
jobs:

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 1 : QUALITÃ‰ DU CODE
  # VÃ©rifie que le code est propre et bien formatÃ©
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  code-quality:
    name: "ðŸ” QualitÃ© du code"
    runs-on: ubuntu-latest

    steps:
      # â”€â”€ Ã‰tape 1 : TÃ©lÃ©charger le code â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # actions/checkout tÃ©lÃ©charge ton repo sur le runner GitHub
      - name: "ðŸ“¥ Checkout du code"
        uses: actions/checkout@v4

      # â”€â”€ Ã‰tape 2 : Installer Python â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "ðŸ Installer Python ${{ env.PYTHON_VERSION }}"
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          # Cache le dossier pip pour accÃ©lÃ©rer les prochaines exÃ©cutions
          cache: "pip"

      # â”€â”€ Ã‰tape 3 : Installer les dÃ©pendances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "ðŸ“¦ Installer les dÃ©pendances"
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black

      # â”€â”€ Ã‰tape 4 : VÃ©rifier le style avec flake8 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # flake8 est un linter : il cherche des erreurs dans le code
      # ex : variables non utilisÃ©es, imports manquants, syntaxe incorrecte
      - name: "âœ… VÃ©rification flake8 (linting)"
        run: |
          flake8 src/ tests/ \
            --max-line-length=100 \
            --exclude=__pycache__ \
            --statistics
          # --statistics : affiche le nombre d'erreurs par type

      # â”€â”€ Ã‰tape 5 : VÃ©rifier le formatage avec black â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # black est un formateur automatique. On vÃ©rifie ici que le code
      # EST DÃ‰JÃ€ correctement formatÃ© (sans modifier les fichiers)
      - name: "âœ… VÃ©rification black (formatage)"
        run: |
          black --check --diff src/ tests/
          # --check : ne modifie rien, retourne une erreur si mal formatÃ©
          # --diff  : affiche exactement ce qui diffÃ¨re


  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 2 : GÃ‰NÃ‰RATION ET VALIDATION DES DONNÃ‰ES
  # GÃ©nÃ¨re les donnÃ©es et vÃ©rifie leur qualitÃ©
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  validate-data:
    name: "ðŸ“Š Validation des donnÃ©es"
    runs-on: ubuntu-latest
    needs: code-quality   # Ce job attend que code-quality soit âœ…

    steps:
      - name: "ðŸ“¥ Checkout du code"
        uses: actions/checkout@v4

      - name: "ðŸ Installer Python ${{ env.PYTHON_VERSION }}"
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: "ðŸ“¦ Installer les dÃ©pendances"
        run: |
          pip install -r requirements.txt

      # â”€â”€ GÃ©nÃ©rer le jeu de donnÃ©es â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # En production, cette Ã©tape serait remplacÃ©e par un tÃ©lÃ©chargement
      # depuis un Data Lake / S3 / Google Cloud Storage
      - name: "ðŸ—ƒï¸ GÃ©nÃ©rer le jeu de donnÃ©es"
        run: |
          python data/generate_data.py

      # â”€â”€ Lancer les tests de donnÃ©es â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # pytest lance automatiquement tous les tests dans tests/test_data.py
      - name: "ðŸ§ª Tests de qualitÃ© des donnÃ©es"
        run: |
          pytest tests/test_data.py \
            -v \
            --tb=short
          # -v       : verbose (dÃ©taillÃ©)
          # --tb=short : afficher un traceback court en cas d'erreur

      # â”€â”€ Sauvegarder les donnÃ©es comme artifact â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Les autres jobs pourront tÃ©lÃ©charger ces donnÃ©es
      - name: "ðŸ’¾ Sauvegarder les donnÃ©es (artifact)"
        uses: actions/upload-artifact@v4
        with:
          name: dataset
          path: data/data.csv
          retention-days: 7


  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 3 : ENTRAÃŽNEMENT ET Ã‰VALUATION DU MODÃˆLE
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  train-and-evaluate:
    name: "ðŸ¤– EntraÃ®nement + Ã‰valuation"
    runs-on: ubuntu-latest
    needs: validate-data   # Ce job attend que validate-data soit âœ…

    steps:
      - name: "ðŸ“¥ Checkout du code"
        uses: actions/checkout@v4

      - name: "ðŸ Installer Python ${{ env.PYTHON_VERSION }}"
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: "ðŸ“¦ Installer les dÃ©pendances"
        run: |
          pip install -r requirements.txt

      # â”€â”€ TÃ©lÃ©charger les donnÃ©es validÃ©es â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # On rÃ©cupÃ¨re l'artifact gÃ©nÃ©rÃ© par le job prÃ©cÃ©dent
      - name: "ðŸ“¥ TÃ©lÃ©charger les donnÃ©es validÃ©es"
        uses: actions/download-artifact@v4
        with:
          name: dataset
          path: data/

      # â”€â”€ EntraÃ®ner le modÃ¨le â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "ðŸ‹ï¸ EntraÃ®ner le modÃ¨le"
        run: |
          python src/train.py

      # â”€â”€ Ã‰valuer les performances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Si accuracy/F1/ROC-AUC sont trop bas, sys.exit(1) stoppe le pipeline
      - name: "ðŸ“ˆ Valider les performances (seuils)"
        run: |
          python src/evaluate.py

      # â”€â”€ Tests sur le modÃ¨le entraÃ®nÃ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "ðŸ§ª Tests du modÃ¨le"
        run: |
          pytest tests/test_model.py \
            -v \
            --tb=short \
            --cov=src \
            --cov-report=term-missing
          # --cov=src          : mesurer la couverture de code du dossier src/
          # --cov-report=term-missing : afficher les lignes non couvertes

      # â”€â”€ Tester les prÃ©dictions en infÃ©rence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "ðŸ”® Tester les prÃ©dictions (infÃ©rence)"
        run: |
          python src/predict.py

      # â”€â”€ Afficher les mÃ©triques dans les logs GitHub â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "ðŸ“‹ Afficher les mÃ©triques finales"
        run: |
          echo "=== MÃ‰TRIQUES DU MODÃˆLE ==="
          cat models/metrics.json

      # â”€â”€ Sauvegarder le modÃ¨le comme artifact â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Le pipeline CD pourra rÃ©cupÃ©rer ce modÃ¨le pour le dÃ©ployer
      - name: "ðŸ’¾ Sauvegarder le modÃ¨le (artifact)"
        uses: actions/upload-artifact@v4
        with:
          name: trained-model-${{ github.sha }}
          # github.sha = l'identifiant unique du commit actuel
          # Chaque modÃ¨le est donc liÃ© Ã  un commit prÃ©cis (traÃ§abilitÃ©)
          path: |
            models/model.pkl
            models/scaler.pkl
            models/metrics.json
          retention-days: 30

      # â”€â”€ RÃ©sumÃ© dans GitHub Actions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Ceci ajoute un rÃ©sumÃ© visible directement dans l'interface GitHub
      - name: "ðŸ“ CrÃ©er un rÃ©sumÃ© dans GitHub"
        run: |
          echo "## ðŸ¤– RÃ©sultats de l'entraÃ®nement" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| MÃ©trique | Valeur |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|--------|" >> $GITHUB_STEP_SUMMARY
          ACCURACY=$(python -c "import json; m=json.load(open('models/metrics.json')); print(f\"{m['accuracy']:.4f}\")")
          F1=$(python -c "import json; m=json.load(open('models/metrics.json')); print(f\"{m['f1_score']:.4f}\")")
          AUC=$(python -c "import json; m=json.load(open('models/metrics.json')); print(f\"{m['roc_auc']:.4f}\")")
          echo "| Accuracy | $ACCURACY |" >> $GITHUB_STEP_SUMMARY
          echo "| F1-Score | $F1 |" >> $GITHUB_STEP_SUMMARY
          echo "| ROC-AUC  | $AUC |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… **Commit** : \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY